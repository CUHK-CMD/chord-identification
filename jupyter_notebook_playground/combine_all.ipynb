{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NCWN0mU1LLJ9"
   },
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import music21\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3TZkyOPAK9o0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#global functions\n",
    "def cal_offset(e):\n",
    "    if e is None:\n",
    "        return 0\n",
    "    return e.offset+cal_offset(e.activeSite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U2dBknN8WRqy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Score:\n",
    "    def __init__(self):\n",
    "        self.beat_list=[Beat()]\n",
    "        \n",
    "    #extract info from note and add to corrsponding beat\n",
    "    def add_note(self,note):\n",
    "        length=note.quarterLength\n",
    "        start=cal_offset(note)\n",
    "        end=start+length\n",
    "        rounded_floor_start=math.floor(start)\n",
    "        #loop until the note played to its end\n",
    "        while start<end-0.000000000001:\n",
    "            if len(self.beat_list)-1<rounded_floor_start:\n",
    "                new_beat=rounded_floor_start-(len(self.beat_list)-1)\n",
    "                #the input note maybe is a chord -> recurse all pitch inside\n",
    "                for _ in range(new_beat):\n",
    "                    self.beat_list.append(Beat())\n",
    "            self.beat_list[rounded_floor_start].add_note(note,min(rounded_floor_start+1-start,end-start))\n",
    "            start+=min(rounded_floor_start+1-start,end-start)\n",
    "            rounded_floor_start=int(start)\n",
    "            \n",
    "    #add key to the first occurence of beat\n",
    "    def add_key(self,note):\n",
    "        assert(note.lyric is not None and '(' in note.lyric)\n",
    "        key_change_beat=cal_offset(note)\n",
    "        rounded_floor_key_change_beat=math.floor(key_change_beat)\n",
    "        self.beat_list[rounded_floor_key_change_beat].add_key(note.lyric.split('(')[0])\n",
    "        \n",
    "    #onyl call once\n",
    "    def infer_key(self):\n",
    "        first_key_in_num=None\n",
    "        first_key_full=None\n",
    "        first_key_major=None\n",
    "        #backtrack\n",
    "        for e in self.beat_list:\n",
    "            if e.key_full is not None:\n",
    "                first_key_full=e.key_full\n",
    "                first_key_in_num=e.key_in_num\n",
    "                first_key_major=e.major\n",
    "                break\n",
    "        #bring forward\n",
    "        for e in self.beat_list:\n",
    "            if e.key_full is None:\n",
    "                e.key_full=first_key_full\n",
    "                e.key_in_num=first_key_in_num\n",
    "                e.major=first_key_major\n",
    "            else:\n",
    "                first_key_full=e.key_full\n",
    "                first_key_in_num=e.key_in_num\n",
    "                first_key_major=e.major\n",
    "                \n",
    "class Beat:\n",
    "    key_mapping={\n",
    "        'C':0,\n",
    "        'D':2,\n",
    "        'E':4,\n",
    "        'F':5,\n",
    "        'G':7,\n",
    "        'A':9,\n",
    "        'B':11\n",
    "    }\n",
    "    def __init__(self):\n",
    "        self.notes = np.zeros((12,7))  #from C1 to C7\n",
    "        self.total_duration = np.zeros((12,7))\n",
    "        self.notes_occurences_count= np.zeros((12,7))\n",
    "        self.key_full=None\n",
    "        self.major=None\n",
    "        self.key_in_num=None\n",
    "    def key2num(self,k):  \n",
    "        k=k.upper()\n",
    "        num=self.key_mapping[k[0]]\n",
    "        modifier=len(k)\n",
    "        if modifier==1:\n",
    "            return num\n",
    "        elif k[1]=='#':\n",
    "            return (num+(modifier-1))%12\n",
    "        elif k[1]=='B' or k[1]=='-' or k[1]=='♭':\n",
    "            return (num-(modifier-1))%12\n",
    "        elif k[1]=='X':\n",
    "            return (num+(modifier-1)*2)%12\n",
    "    def add_note(self,note,duration):\n",
    "        assert(duration<=1)\n",
    "        pitches=note.pitches\n",
    "        for pitch in pitches:\n",
    "            pitch_idx=self.key2num(pitch.nameWithOctave[:-1])\n",
    "            octave=int(pitch.nameWithOctave[-1])-1\n",
    "            if octave<0:\n",
    "                octave=0\n",
    "            elif octave>6:\n",
    "                octave=6\n",
    "            self.notes[pitch_idx,octave]=1\n",
    "            self.total_duration[pitch_idx,octave]+=duration\n",
    "            self.notes_occurences_count[pitch_idx,octave]+=1\n",
    "            \n",
    "    def add_key(self,k):\n",
    "        self.major = 'M' in k\n",
    "        self.key_full=k\n",
    "        k=k[:-1]\n",
    "        self.key_in_num=self.key2num(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "trDx92pfWVFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train ../musicxml(train)\\Fugue_in_G_Minor.mxl\n",
      "train ../musicxml(train)\\G_minor.mxl\n",
      "train ../musicxml(train)\\Menuet_in_G_Minor.mxl\n",
      "train ../musicxml(train)\\Minuet_in_F.mxl\n",
      "train ../musicxml(train)\\Minuet_in_G_Major.mxl\n",
      "train ../musicxml(train)\\Moonlight_Sonata_1st_Movement.mxl\n",
      "train ../musicxml(train)\\Musette_in_D.mxl\n",
      "train ../musicxml(train)\\Nocturne_in_B_Major.mxl\n",
      "train ../musicxml(train)\\Nocturne_in_C#_Minor.mxl\n",
      "train ../musicxml(train)\\Nocturne_in_Eb_Major.mxl\n",
      "train ../musicxml(train)\\Nocturne_in_E_Minor.mxl\n",
      "train ../musicxml(train)\\Nocturne_in_F#_Major.mxl\n",
      "train ../musicxml(train)\\Nocturne_no._1.mxl\n",
      "train ../musicxml(train)\\Nocturne_No._20_in_C#_Minor.mxl\n",
      "train ../musicxml(train)\\Prélude_in_A_Major.mxl\n",
      "train ../musicxml(train)\\Prélude_in_B_Major.mxl\n",
      "train ../musicxml(train)\\Prélude_in_B_Minor.mxl\n",
      "train ../musicxml(train)\\Prélude_in_B_Minor_op104a.mxl\n",
      "train ../musicxml(train)\\Prélude_in_Db_Major.mxl\n",
      "train ../musicxml(train)\\Prélude_in_E_Minor.mxl\n",
      "train ../musicxml(train)\\Prélude_in_F#_Major.mxl\n",
      "train ../musicxml(train)\\Prélude_in_G_Major.mxl\n",
      "train ../musicxml(train)\\Solfeggietto_in_C_minor.mxl\n",
      "train ../musicxml(train)\\sonata_no_1.mxl\n",
      "train ../musicxml(train)\\Sonate_No._28.mxl\n",
      "train ../musicxml(train)\\Sonate_No._28_1stmovt.mxl\n",
      "train ../musicxml(train)\\Sonate_No._31.mxl\n",
      "train ../musicxml(train)\\Sonatina_in_G.mxl\n",
      "train ../musicxml(train)\\Spring_Waltz.mxl\n",
      "train ../musicxml(train)\\Twinkle-Twinkle.mxl\n",
      "train ../musicxml(train)\\Waltz.mxl\n",
      "train ../musicxml(train)\\Waltz_in_Eb_Major.mxl\n",
      "train ../musicxml(train)\\Étude_in_F_Major.mxl\n",
      "train ../musicxml(train)\\Étude_in_F_Minor.mxl\n",
      "train ../musicxml(train)\\Étude_in_Gb_Major.mxl\n",
      "train ../musicxml(train)\\Étude_in_Gb_Major_Op25.mxl\n",
      "test ../musicxml(test)\\Il_Vecchio_Castello.mxl\n",
      "test ../musicxml(test)\\Piano_Sonata_No._11.mxl\n",
      "test ../musicxml(test)\\Prélude_in_C_Minor.mxl\n",
      "test ../musicxml(test)\\Waltz_in_A_Minor.mxl\n",
      "test ../musicxml(test)\\Étude_in_C_Minor.mxl\n"
     ]
    }
   ],
   "source": [
    "#load data beat by beat\n",
    "all_score_train=[]\n",
    "all_score_test=[]\n",
    "all_score=[]\n",
    "files=[\"../musicxml(train)/*.mxl\",\"../musicxml(test)/*.mxl\"]\n",
    "for piece in glob.glob(files[0]):\n",
    "    all_score.append(piece)\n",
    "    all_beat_train=Score()\n",
    "    all_score_train.append(all_beat_train)\n",
    "    print('train',piece)\n",
    "    chords = []\n",
    "    notes = []\n",
    "    c = converter.parse(piece)\n",
    "    post = c.flat\n",
    "\n",
    "    #extract note\n",
    "    for note in post.notes:\n",
    "        all_beat_train.add_note(note)\n",
    "        if note.lyric is not None and '(' in note.lyric:\n",
    "            all_beat_train.add_key(note)\n",
    "\n",
    "    all_beat_train.infer_key()\n",
    "for piece in glob.glob(files[1]):\n",
    "    all_score.append(piece)\n",
    "    all_beat_test=Score()\n",
    "    all_score_test.append(all_beat_test)\n",
    "    print('test',piece)\n",
    "    chords = []\n",
    "    notes = []\n",
    "    c = converter.parse(piece)\n",
    "    post = c.flat\n",
    "\n",
    "    #extract note\n",
    "    for note in post.notes:\n",
    "        all_beat_test.add_note(note)\n",
    "        if note.lyric is not None and '(' in note.lyric:\n",
    "            all_beat_test.add_key(note)\n",
    "\n",
    "    all_beat_test.infer_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QBWqkKO9WYNa"
   },
   "outputs": [],
   "source": [
    "#turns each beat to a vector\n",
    "weight=[1.35,1.25,0.9,0.95,0.8,0.75,0.7]\n",
    "\n",
    "trainX=[]\n",
    "trainY=[]\n",
    "for e in all_score_train:\n",
    "    tempX=[]\n",
    "    tempY=[]\n",
    "    count=0\n",
    "    for beat in e.beat_list:\n",
    "        value=beat.total_duration*beat.notes_occurences_count\n",
    "        if np.sum(value)!=0:\n",
    "            value/=np.sum(value)\n",
    "            value*=weight\n",
    "            value=value.sum(axis=1)\n",
    "            #value=value.reshape((-1))\n",
    "            value/=value.sum()\n",
    "        else:\n",
    "            value=np.zeros((12))\n",
    "            \n",
    "        assert(len(value)==12)\n",
    "        tempX.append(value)\n",
    "        \n",
    "        prepare_y=np.zeros((13,1))\n",
    "        prepare_y[-1]=beat.major*1\n",
    "        prepare_y[beat.key_in_num]=1\n",
    "        assert(len(prepare_y)==13)\n",
    "        tempY.append(prepare_y)\n",
    "        count+=1\n",
    "    trainX.append(tempX)\n",
    "    trainY.append(tempY)\n",
    "\n",
    "testX=[]\n",
    "testY=[]\n",
    "for e in all_score_test:\n",
    "    tempX=[]\n",
    "    tempY=[]\n",
    "    count=0\n",
    "    for beat in e.beat_list:\n",
    "        value=beat.total_duration*beat.notes_occurences_count\n",
    "        if np.sum(value)!=0:\n",
    "            value/=np.sum(value)\n",
    "            value*=weight\n",
    "            value=value.sum(axis=1)\n",
    "            #value=value.reshape((-1))\n",
    "            value/=value.sum()\n",
    "        else:\n",
    "            value=np.zeros((12))\n",
    "            \n",
    "        assert(len(value)==12)\n",
    "        tempX.append(value)\n",
    "        \n",
    "        prepare_y=np.zeros((13,1))\n",
    "        prepare_y[-1]=beat.major*1\n",
    "        prepare_y[beat.key_in_num]=1\n",
    "        assert(len(prepare_y)==13)\n",
    "        tempY.append(prepare_y)\n",
    "        count+=1\n",
    "    testX.append(tempX)\n",
    "    testY.append(tempY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KseP4qOaWY9C"
   },
   "outputs": [],
   "source": [
    "#generate training segments, ordered in score\n",
    "look_forward=4\n",
    "look_after=4\n",
    "dataX,dataY=[],[] #train\n",
    "dataXX,dataYY=[],[] #test\n",
    "for idx_p,piece in enumerate(trainX):\n",
    "    piece_notesX=[]\n",
    "    piece_notesY=[]\n",
    "    for idx_b,beat in enumerate(piece):\n",
    "        tempX=[]\n",
    "        tempfront=[]\n",
    "        tempend=[]\n",
    "        for i in reversed(range(1,look_forward+1)):\n",
    "            if(idx_b-i)<0:\n",
    "                tempfront.append(np.zeros(12))\n",
    "            else:\n",
    "                tempfront.append(np.array(piece[idx_b-i]))\n",
    "        tempfront=np.array(tempfront)\n",
    "        tempfront=np.sum(tempfront,axis=0)\n",
    "          \n",
    "        tempX.append(tempfront)\n",
    "        tempX.append(piece[idx_b])\n",
    "\n",
    "        for i in range(1,look_after+1):\n",
    "            if(idx_b+i)>len(piece)-1:\n",
    "                tempend.append(np.zeros(12))\n",
    "            else:\n",
    "                tempend.append(np.array(piece[idx_b+i]))\n",
    "\n",
    "        tempend=np.sum(tempend,axis=0) \n",
    "        tempX.append(tempend)\n",
    "\n",
    "        piece_notesX.append(tempX)\n",
    "        piece_notesY.append(trainY[idx_p][idx_b])\n",
    "    dataX.append(piece_notesX)\n",
    "    dataY.append(piece_notesY)\n",
    "\n",
    "for idx_p,piece in enumerate(testX):\n",
    "    piece_notesX=[]\n",
    "    piece_notesY=[]\n",
    "    for idx_b,beat in enumerate(piece):\n",
    "        tempX=[]\n",
    "        tempfront=[]\n",
    "        tempend=[]\n",
    "        for i in reversed(range(1,look_forward+1)):\n",
    "            if(idx_b-i)<0:\n",
    "                tempfront.append(np.zeros(12))\n",
    "            else:\n",
    "                tempfront.append(np.array(piece[idx_b-i]))\n",
    "        tempfront=np.array(tempfront)\n",
    "        tempfront=np.sum(tempfront,axis=0)\n",
    "          \n",
    "        tempX.append(tempfront)\n",
    "        tempX.append(piece[idx_b])\n",
    "\n",
    "        for i in range(1,look_after+1):\n",
    "            if(idx_b+i)>len(piece)-1:\n",
    "                tempend.append(np.zeros(12))\n",
    "            else:\n",
    "                tempend.append(np.array(piece[idx_b+i]))\n",
    "\n",
    "        tempend=np.sum(tempend,axis=0) \n",
    "        tempX.append(tempend)\n",
    "\n",
    "        piece_notesX.append(tempX)\n",
    "        piece_notesY.append(testY[idx_p][idx_b])\n",
    "    dataXX.append(piece_notesX)\n",
    "    dataYY.append(piece_notesY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zaFqwKoSk6oq"
   },
   "outputs": [],
   "source": [
    "#turn the training/testing data(ordered in score) to tranable format(ordered in segments)\n",
    "def trainable(X,Y):\n",
    "  retX=[ b for x in X for b in x ]\n",
    "  retX=np.array(retX)\n",
    "  retY=[b for y in Y for b in y]\n",
    "  retY=np.array(retY).reshape((-1,13))\n",
    "  return retX,retY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM model (Key prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nqhRCzDWWdbq"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2LxAkFAAWeMq"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ufyJxwzWkMiY"
   },
   "outputs": [],
   "source": [
    "#lstm model\n",
    "def get_model():\n",
    "  in_data = Input(shape=(3,12))\n",
    "\n",
    "  lstm = LSTM(128,return_sequences=True)(in_data)#\n",
    "  lstm = LSTM(12)(lstm)\n",
    "  lstm = Flatten()(lstm)\n",
    "\n",
    "\n",
    "  #lstm_2 = Dense(4,activation='relu')(lstm)\n",
    "  #lstm_2 = Dense(2,activation='relu')(lstm_2)\n",
    "  output2=Dense(1,activation='sigmoid',name='majorPrediction')(lstm)\n",
    "\n",
    "  keyclassifier = Dense(64,activation='relu')(lstm)\n",
    "  output=Dense(12,activation='softmax',name='keyPrediction')(lstm)\n",
    "  \n",
    "\n",
    "  model = Model(inputs=in_data, outputs=[output,output2])\n",
    "\n",
    "  losses ={\n",
    "          'keyPrediction':'categorical_crossentropy',\n",
    "          'majorPrediction':'binary_crossentropy'    \n",
    "        }\n",
    "\n",
    "  lossWeights={\n",
    "          'keyPrediction':0.7,\n",
    "          'majorPrediction':0.3  \n",
    "        }\n",
    "      \n",
    "  model.compile(  loss=losses,\n",
    "                loss_weights= lossWeights,\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "callback=EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=30, verbose=2, mode='auto',\n",
    "    baseline=None, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#HMM model(chord prediction)\n",
    "import sys\n",
    "sys.path.append('../modules')\n",
    "import HMM\n",
    "h_states=[#Minor\n",
    "      'MinorI', 'MinorI+',\n",
    "      'MinorbII', 'MinorII',\n",
    "      'MinorIII',\n",
    "      'MinorIV', 'MinorIV+',\n",
    "      'MinorV', 'MinorV+',\n",
    "      'MinorVI', 'MinorGerVI', 'MinorFreVI', 'MinorItaVI',\n",
    "      'MinorVII', 'MinorDimVII',\n",
    "      #Major\n",
    "      'MajorI',\n",
    "      'MajorbII','MajorII',\n",
    "      'MajorIII',\n",
    "      'MajorIV',\n",
    "      'MajorV',\n",
    "      'MajorbVI','MajorGerVI','MajorFreVI','MajorItaVI','MajorVI',\n",
    "      'MajorVII'\n",
    "]\n",
    "\n",
    "def prepareHMM(K_fold_selection):\n",
    "  #  print(all_score[K_fold_selection[0]])\n",
    "    pieces=[all_score[e] for e in K_fold_selection]\n",
    "    HMM_data=[]\n",
    "    current_chord=None\n",
    "    current_key=None\n",
    "    HMM_notes=[]\n",
    "    HMM_chord=[]\n",
    "    HMM_beats=[]\n",
    "    for piece in pieces:\n",
    "        data_chord=[]\n",
    "        data_notes=[]\n",
    "        data_beats=[]\n",
    "        c = converter.parse(piece)\n",
    "        all_notes=[]\n",
    "        for el in c.recurse().notes:\n",
    "            if el.lyric is not None:\n",
    "                el.lyric=el.lyric.replace('♭','b')\n",
    "            all_notes.append([el.lyric, el, cal_offset(el),el.duration.linked])\n",
    "        \n",
    "        \n",
    "        #sort by first occurence\n",
    "        b=sorted(all_notes,key=lambda x: (x[-2],x[0] if x[0] is not None else \"ZZZZZZZZZZZZZZZ\"))\n",
    "        data_note={}\n",
    "        for e in b:\n",
    "   \n",
    "            if current_chord is None and e[0] is None:\n",
    "                continue\n",
    "            elif e[0] is not None:\n",
    "                if '(' in e[0]:\n",
    "                    current_key=e[0].split('(')[0]\n",
    "                    current_chord=e[0].split('(')[1].split(')')[0]\n",
    "                else:\n",
    "                    current_key=current_key\n",
    "                    current_chord=e[0]\n",
    "             \n",
    "                major='M' if 'M' in current_key else 'm'\n",
    "                \n",
    "                chord=current_key[:-1]+major+'_'+current_chord\n",
    "                data_chord.append(chord)\n",
    "                data_beats.append(e[2])\n",
    "                s=0\n",
    "                for k,v in data_note.items():\n",
    "                    s+=v\n",
    "                for k,v in data_note.items():\n",
    "                    data_note[k]=v/s\n",
    "                data_notes.append(data_note)\n",
    "                data_note={}\n",
    "\n",
    "            for pitch in e[1].pitches:\n",
    "                if pitch.name in data_note:\n",
    "                    data_note[pitch.name]+=e[1].quarterLength*weight[int(pitch.nameWithOctave[-1])-1]\n",
    "                    data_note[pitch.name]*=1.2 #reward for occurence\n",
    "                else:\n",
    "                    data_note[pitch.name]=e[1].quarterLength*weight[int(pitch.nameWithOctave[-1])-1]\n",
    "\n",
    "        data_notes=data_notes[1:]\n",
    "        data_notes.append(data_note)\n",
    "        HMM_notes.append(data_notes)\n",
    "        HMM_chord.append(data_chord)\n",
    "        HMM_beats.append(data_beats)\n",
    "        \n",
    "        \n",
    "    return HMM_notes,HMM_chord,HMM_beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools for evaluation\n",
    "from chordToNote import *\n",
    "chords=['C','Db','D','Eb','E','F','F#','G','Ab','A','Bb','B']\n",
    "M=['Minor','Major']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 506
    },
    "id": "u_4pdCEjGq1v",
    "outputId": "4a4115c9-84ed-4a18-9d87-e278875b6a0c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-6da55467a76f>:15: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  k_fold_x=np.array(k_fold_x)\n",
      "<ipython-input-14-6da55467a76f>:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  k_fold_y=np.array(k_fold_y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n"
     ]
    }
   ],
   "source": [
    "#K- fold crossvalidation\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds=10\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_no = 1\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "acc2_per_fold=[]\n",
    "acc3_per_fold=[]\n",
    "\n",
    "k_fold_x=dataX+dataXX\n",
    "k_fold_y=dataY+dataYY\n",
    "k_fold_x=np.array(k_fold_x)\n",
    "k_fold_y=np.array(k_fold_y)\n",
    "\n",
    "HMM_score=0\n",
    "HMM_count=0\n",
    "\n",
    "for train, test in kfold.split(k_fold_x, k_fold_y):\n",
    "\n",
    "  model=get_model()\n",
    "\n",
    "  processedX,processedY=trainable(k_fold_x[train],k_fold_y[train])\n",
    "  processedXX,processedYY=trainable(k_fold_x[test],k_fold_y[test])\n",
    "\n",
    "  #sample_weights\n",
    "  classes={}\n",
    "  s=0\n",
    "  for e,m in zip(processedY[:,:-1],processedY[:,-1]):\n",
    "    s+=1\n",
    "    name=str(np.argmax(e))+' '+str(int(m))\n",
    "    if name in classes:\n",
    "      classes[name]+=1\n",
    "    else:\n",
    "      classes[name]=1\n",
    "\n",
    "  for e in classes:\n",
    "    classes[e]=s / (24 * classes[e])\n",
    "\n",
    "  sample_weights=[]\n",
    "  for e,m in zip(processedY[:,:-1],processedY[:,-1]):\n",
    "    name=str(np.argmax(e))+' '+str(int(m))\n",
    "    sample_weights.append(classes[name])\n",
    "  sample_weights=np.array(sample_weights)\n",
    "  sample_weights.shape\n",
    "\n",
    "\n",
    "\n",
    "  # start K-fold\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  \n",
    "\n",
    "  # Fit data to model\n",
    "  history = model.fit(processedX, [processedY[:,:-1],processedY[:,-1]],\n",
    "                      validation_data=(processedXX, [processedYY[:,:-1],processedYY[:,-1]]),\n",
    "                      verbose=0, \n",
    "                      epochs=1000,\n",
    "                      sample_weight=sample_weights,\n",
    "                      callbacks=[callback],  \n",
    "                      batch_size=1024,\n",
    "                      shuffle=True)\n",
    "\n",
    "  # Generate generalization metrics \n",
    "  # use different score explictly\n",
    "  scores = model.evaluate(processedXX, [processedYY[:,:-1],processedYY[:,-1]], verbose=0)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[3]} of {scores[3]*100}%; {model.metrics_names[4]} of {scores[4]*100}%')\n",
    "\n",
    "  # evaluate key prediction\n",
    "  a,b=(model.predict(processedXX))\n",
    "  key_count_all=0\n",
    "  correct=0\n",
    "  fifth=0\n",
    "  parallel=0\n",
    "  relative=0\n",
    "  for idx,e in enumerate(processedYY):\n",
    "      #exact match\n",
    "      key_count_all+=1\n",
    "      if np.argmax(processedYY[idx][:-1])==np.argmax(a[idx]) and processedYY[idx][-1]==(1 if b[idx]>=0.5 else 0):\n",
    "          correct+=1\n",
    "      else:\n",
    "          if (np.argmax(processedYY[idx][:-1])+7)%12==np.argmax(a[idx]) and processedYY[idx][-1]==(1 if b[idx]>=0.5 else 0):\n",
    "                fifth+=1\n",
    "          elif np.argmax(processedYY[idx][:-1])==np.argmax(a[idx]) and processedYY[idx][-1]!=(1 if b[idx]>=0.5 else 0):\n",
    "                parallel+=1\n",
    "          elif processedYY[idx][-1]!=(1 if b[idx]>=0.5 else 0):\n",
    "                if (1 if b[idx]>=0.5 else 0)==0:\n",
    "                    if np.argmax(processedYY[idx][:-1])==((np.argmax(a[idx])+3)%12):\n",
    "                        relative+=1\n",
    "                elif np.argmax(processedYY[idx][:-1])==((np.argmax(a[idx])-3)%12):\n",
    "                    relative+=1\n",
    "  print('Correct:',correct,'Fifth:',fifth,'Relative:',relative,'parallel:',parallel,'Wrong:',key_count_all-correct-fifth-relative-parallel)\n",
    "  print('Acc:',correct/(key_count_all),'weighted Acc:',(correct+0.5*fifth+0.3*relative+0.2*parallel)/key_count_all)\n",
    "\n",
    "  #log acc of key_prediction\n",
    "  acc_per_fold.append(((correct+0.5*fifth+0.3*relative+0.2*parallel)/key_count_all)* 100)\n",
    "  acc2_per_fold.append(scores[3]* 100)\n",
    "  acc3_per_fold.append(scores[4]* 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "  \n",
    "  #prepare HMM model\n",
    "  n,c,_=prepareHMM(train)\n",
    "  hmm_model=HMM.HMM(len(h_states),2,h_states,[\"outside chord\",\"inside chord\"])\n",
    "  hmm_model.train_supervisied(n,c)#initialize parameter\n",
    "\n",
    "\n",
    "  #prepare HMM test data\n",
    "  testnotes,c,offsets=prepareHMM(test)\n",
    "  key_name_scores=[]\n",
    "  for test_id,test_piece in enumerate(offsets):\n",
    "    o1,o2=model.predict(np.array(k_fold_x[test[test_id]]))\n",
    "    key_name_score=[]\n",
    "    #append len at end\n",
    "    test_piece.append(len(o1))\n",
    "    trace_id=0\n",
    "    for i in range(len(test_piece)-1):\n",
    "        temp=[]\n",
    "        #add predicted key to bag\n",
    "        while trace_id<test_piece[i+1]:\n",
    "            if (o2[trace_id][0]>=0.5)*1==0:\n",
    "                name=chords[np.argmax(o1[trace_id])].lower()+M[(o2[trace_id][0]>=0.5)*1]\n",
    "            else:\n",
    "                name=chords[np.argmax(o1[trace_id])]+M[(o2[trace_id][0]>=0.5)*1]\n",
    "            temp.append(name)\n",
    "            trace_id+=1\n",
    "        if len(temp)==0:\n",
    "            #follow previous pred\n",
    "            key_name_score.append(key_name_score[-1])\n",
    "        else:\n",
    "            #majority vote from bag\n",
    "            key_name_score.append(max(set(temp), key = temp.count))\n",
    "    key_name_scores.append(key_name_score)\n",
    "\n",
    "  #predict on HMM + evaluation\n",
    "  for test_i in range(len(testnotes)):\n",
    "        \n",
    "        \n",
    "      prediction=hmm_model.predict(testnotes[test_i],key_name_scores[test_i])\n",
    "      prediction=[h_states[i] for i in prediction]\n",
    "      predict_result=[]\n",
    "      for pKey,p in zip(key_name_scores[test_i],prediction):\n",
    "        if pKey=='gbMinor':\n",
    "            pKey='f#Minor'\n",
    "        elif pKey=='dbMinor':\n",
    "            pKey='c#Minor'\n",
    "        elif pKey=='abMinor':\n",
    "            pKey='g#Minor'\n",
    "        elif pKey=='d#Minor':\n",
    "            pKey='ebMinor'\n",
    "        #print(pKey, p[5:])\n",
    "        p=p[5:]\n",
    "        p=p.replace('7','')\n",
    "        p=p.replace('Dim','DimVII')\n",
    "        predict_result.append(ChordToNote(pKey, p))\n",
    "        \n",
    "        \n",
    "      ground_result=[]\n",
    "      for pKey in c[test_i]:\n",
    "        m,p=pKey.split('_')\n",
    "        m+='ajor' if 'M' in m else 'inor'\n",
    "        if m=='Gbminor':\n",
    "            m='F#minor'\n",
    "        elif m=='Dbminor':\n",
    "            m='C#minor'\n",
    "        elif m=='Abminor':\n",
    "            m='g#minor'\n",
    "        elif m=='D#minor':\n",
    "            m='ebminor'\n",
    "        p=p.replace('7','')\n",
    "        p=p.replace('Dim','DimVII')\n",
    "        ground_result.append(ChordToNote(m, p))\n",
    "        \n",
    "        \n",
    "      correct=0\n",
    "      all=0\n",
    "      for a,b in zip(predict_result,ground_result):\n",
    "        all+=1\n",
    "        if a[0]==b[0]:\n",
    "            correct+=1\n",
    "      print(all_score[test[test_i]],correct/all)\n",
    "      HMM_score+=correct/all\n",
    "      HMM_count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc: key+chord prediction\n",
    "HMM_score/HMM_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qluCV4HtIYyH"
   },
   "outputs": [],
   "source": [
    "# == key prediction ACC==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Key&Maj Hierarchical Accuracy: {acc_per_fold[i]}% - Key Accuracy: {acc2_per_fold[i]}% - Maj Accuracy: {acc3_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Total Hierarchical Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> KeyAccuracy: {np.mean(acc2_per_fold)} (+- {np.std(acc2_per_fold)})')\n",
    "print(f'> MajAccuracy: {np.mean(acc3_per_fold)} (+- {np.std(acc3_per_fold)})')\n",
    "print(f'> Total Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "key identification & segmentation2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
